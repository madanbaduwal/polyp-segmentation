A Systematic Analysis of DL and ML Models for
Plant Disease Detection
Ishita Saxena CSE, Amity School of Engineering and Technology, Amity University Noida, India ishitasaxena2907@gmail.com
Lakshika Bhagat CSE, Amity School of Engineering and Technology. Amity University Noida, India lakshikabhagat23@gmail.com
Neha Tyagi CSE, Amity School of Engineering and Technology, Amity University Noida, India nehaanujtyagi@gmail.com
Abstract—Plants play a requisite role in human growth and survival. Since time immemorial, the farmers have faced the problem of crop failure due to diseases or pests which has resulted in a huge loss of both money and effort to the farmers. Plant Disease is a major threat to almost all types of plants and affecting food security across the world. The long-established plant disease detection system is a wearisome process and is also not applicable to the wider plantation size, thus reducing crop production. Thus, it is essential to incorporate smart agricultural methodologies to detect plant disease at an early stage and applicable to mass production resulting in finer quality of plants. Through this paper we aim to research on various techniques which are now in use in development of a system to spot the different types of plant diseases and suggest recommended actions to the farmers that can improve the quality of their crops at an initial stage and help in better yield. This paper presents an extensive review of deep machine learning models which are proposed to spot various plants disorders using modern detection techniques.
Keywords—Machine Learning, Deep Learning, Convolutional Neural Networks.
I. INTRODUCTION
Plant diseases are considered as a significant problem for the world's agriculture in terms of ensuring food production and preserving economies. The majority of plant disease discerning and supervision techniques have been manual, involving visual inspection by qualified agronomists. These methods are labourintensive, time-consuming, and frequently prone to human mistake, notwithstanding their relative effectiveness. Additionally, more effective agricultural methods and larger food yields are required due to the growing world population. The core objective of various Plant Disease Detection Systems is to provide farmers, agronomists, and agricultural stakeholders with a user-friendly tool that can rapidly and accurately identify the diseases affecting their crops. By simply capturing images of plant samples, users can receive instant diagnostic results, including the name of the disease and recommended treatments or interventions. For the purpose of mechanising the identification of plant illnesses, this paper reviews various intelligent systems that makes use of machine learning algorithms, specifically convolutional neural networks (CNNs). CNNs, a subset of deep learning models, are renowned for their extraordinary capacity for image analysis and interpretation. These state-of-the-art methods allow us to train a model to
identify particular disease patterns and symptoms in plants by analysing photos of their leaves, stems, or fruits.
II. MACHINE LEARNING AND DEEP LEARNING TECHNIQUES
Various techniques involving machine learning are used in spotting plant diseases since long time. Earlier various models utilized for predicting diseases in plants were based on the concept of drawing out features and classifying them. These methods have been used extensively in detecting diseases like powdery mildew, rust, and leaf blotch, and in addition to this these methods are also used in predicting disease symptoms occurring due to nutrient deficiency and drought. The machine learning models however were replaced by the deep learning models using deep belief networks and convolutional neural networks because machine learning models had their own limitations and were not very impactful in disease detection in early stages and some of the symptoms were not even detected by the model.
Deep learning models are nothing but neural networks which are modelled just like the neurons in the human brain. These networks have multiple layers which work together to solve highly complex problems. These layers use mathematical calculations to produce output through the multiple hidden layers from the input data. These hidden layers help comprehend even unstructured data and make some general predictions without using the classical feature extraction. Table I describes models which are utilized in the development of detection systems for predicting plant disorders.
TABLE I. An Overview Of Models Used In Developing Detection Systems.
Algorithms Description Convolution al Neural Network
Widely used for spatial feature extraction. Effective for detecting the disorders in plants based on leaf images. Transfer Learning Making use of already trained models (e.g., ResNet) for balancing on plant disease datasets for improved performance. Recurrent Neural Networks
Less common but applicable for tasks involving temporal data, such as the progression of symptoms over time. Capsule Networks Designed to address limitations of CNNs, particularly in handling spatial hierarchies and part-whole relationships. Attention Mechanisms Used to focus on relevant parts of an image,
2024 International Conference on Computing, Power, and Communication Technologies (IC2PCT)
Copyright © IEEE–2024 ISBN: 979-8-3503-8354-6 906
2024 IEEE International Conference on Computing, Power and Communication Technologies (IC2PCT) | 979-8-3503-8354-6/24/$31.00 ©2024 IEEE | DOI: 10.1109/IC2PCT60090.2024.10486212
Authorized licensed use limited to: University of Texas of the Permian Basin. Downloaded on September 20,2024 at 10:01:59 UTC from IEEE Xplore. Restrictions apply.


beneficialfor plant disease detection, especially when specific regions matter. Generative Adversarial Networks
Applied for data augmentation and to generate synthetic images.
III. PLANT DISEASE DETECTION: A REVIEW OF APPROACHES IN USE
A. AlexNet
One of the major technologies used nowadays in the development of detection systems is using the different types of convolutional neural networks. The first model [3] being discussed here is developed using AlexNet. AlexNet is developed in the year 2012 [4]. It is a type of network that uses convolutions. The model [3] in this paper was built exclusively to determine and detect the diseases in tomato leaves. AlexNet is a neural network that makes use of deep convolutions and which was implemented specifically to deal with wide-ranging coloured images, and it has more than 62 million trainable parameters. The AlexNet model in this paper [3] has eleven layers. After implementation the model was found to be accurate by 96 percent, with a recall worth 95 percent, a precision worth 98 percent and F-measure worth 97 percent. The model could be implemented in android gadgets where farmers or users can upload the pictures of the infected plant leaves and the model can predict resulting diseases. The main con of this system is that the model works only for the detection of diseases on tomato leaves and a generalized model for all plants needs to be developed. Fig 1 represents the architecture of AlexNet [22].
B. ResNet
The problem with the AlexNet architecture was that it worked efficiently for the small number of layers but as the number of layers was increased a new problem called exploding or vanishing gradient arised. This problem meant that with the multiplying number of layers, the training and the test error rate also rises which caused the gradient to become 0 or too large. To solve this problem, researchers at Microsoft Research introduced the concept of Residual Network in 2015. The model in paper[5] has been developed using the ResNet which shows that there is an improve in the performance of disease detection system which was previously unsatisfactory in the case of AlexNet. In this model, the wheat disease plant is detected using ResNet-50 and a SVM classifier which increased the rate of detecting wheat-based plant diseases by giving effective prediction with accurate results.
Fig. 1. Architecture of AlexNet [22].
C. GoogleNet
GoogleNet also known as inception net which first came into existence in 2014. The Inception component is a crucial fragment of the Inception network. The Inception component is composed of several convolutional filters of various sizes placed next to one another. The dimension reduction method used is a 1x1 convolutional operation. GoogleNet is a 22-layer network made up primarily of Inception modules stacked on top of one another using stride 2 and max-pooling layers to cut the resolution in half grid [7]. The model in paper[6] is developed using GoogLeNet.A public database including approximately 54,300 photos of fourteen different crop kinds and the disorders that affect them is used to train the machine. In a crop identification and protection implementation, it can be further deployed because it achieves a precision worth 97.82% for fourteen crop varieties. The model [6] architecture with the highest success rate, GoogleNet, has a success percentage of 97.82%. In this instance, GoogleNet has shown to be the best for the experiments conducted. Farmers can utilise this as a useful instrument to safeguard plants against illnesses and create a workable supplemental technique that aids in preventing losses in food production.
D. DenseNet
A DenseNet [8] is a neural network made up of deep convolutions that makes use of condensed interconnections between layers by interconnecting all layers (with complementing feature-map dimensions) directly with each other using condensed blocks. Each layer acquires extra throughputs from all previous layers and disseminates its own feature-maps to the following layers for the purpose of maintaining the anticipating and look-ahead properties of the system.
A learning model based on transfer learning for spotting illnesses in the leaves of plants is presented in the paper[9] . This work proposes DenseNet201, a classifier that makes use of convolutional network and is built by re-using already developed learning models. The used pictures collection contains 28310 leaf shots from three different crops— potato, pepper, and tomato—divided into 15 different classes, including 2 classes for potato disorders and 1 class for healthy conditions, 9 classes for tomato disorders and 1 class for healthy conditions, and 1 class for pepper disorders. The proposed model, as stated by the results of the observations [9], has the greatest precision of approximately 99.4 percentage for training and precision of approximately 98.7 percentage for validation. In paper [9], authors have suggested prototype based on an already trained model and convolutional neural network. Pre- trained architecture is used in the suggested model in order to offer the highest accuracy among other models. CNN is used for classification of features. The validation lot and test lot are used to evaluate the prototype.
E. VGGNet
VGGNet is a dense architecture that makes use of neural networks and is designed for classifying images. It was developed by researchers at the University of Oxford and was introduced in a paper by Karen Simonyan and Andrew
2024 International Conference on Computing, Power, and Communication Technologies (IC2PCT)
Copyright © IEEE–2024 ISBN: 979-8-3503-8354-6 907
Authorized licensed use limited to: University of Texas of the Permian Basin. Downloaded on September 20,2024 at 10:01:59 UTC from IEEE Xplore. Restrictions apply.


Zisserman [10]. VGGNet played a significant role in the advancement of computer vision. VGGNet uses fully connected levels after a number of max-pooling levels and convolutional levels to create predictions. Typically, the ending level comprises one thousand segments, that correspond to onethousand classes in the dataset of ImageNet (the dataset it was initially intended for). The network uses Rectified Linear Units (ReLU) as activation functions. In the 2014 ILSVRC[10], VGGNet produced cutting-edge results, showcasing the productiveness of neural networks using deep convolutions for picture categorization. VGGNet is less useful for real- time applications than subsequent, more effective architectures like Google's Inception and ResNet because of its high processing cost caused by its depth. Despite this, VGGNet continues to mark a crucial turning point in the development of neural networks using convolution and deep learning.
F. CNN
The systems used for identifying the plant disorders have made extensive use of convolutional neural networks (CNNs), which have depicted considerable potentiality in this field. CNNs are a category of prototypes using deep learning that are excellent at tasks requiring image identification, making them suitable for identifying plant diseases from photos of leaves.
The authors in paper[11] carry out an instantaneous categorization of plant disorders, offering a picture sensor including a convolutional neural network with limited resources built in the Cam H7 Plus software. The resulting CNN network has been apprenticed on 2 different datasets, the PlantVillage-augmented data collection set and the ESCA-data collection set, and carried out in a small-potency, small-price Python configurable automation observation camera for instantaneous image categorization and accession.
The image locator [11] can be successfully carried out for the selected system with limited resources, accomplishing a precision of about approximately 95.24%/98.10% with a very low inference time (125.630 ms/122.969 ms) and low memory cost (735.727 KB/718.961 KB) verified for the PlantVillageaugmented data collections and ESCA, respectively. This enables the configuration of a transferrable implanted system for the classifying disorders in plant leaves.
G. R-CNN
"Region-based Convolutional Neural Network," is a framework for computer vision and entity recognition that was developed to tackle the issue of object detection in images.
Fig. 2. Architecture of R-CNN [21].
A pertinent innovation in the area of entity detection was RCNN. To precisely find and categorize objects in images, it combines the strength of convolutional neural networks (CNNs) with region proposal methods. Fig 2 shows a basic architecture of the R-CNN model.
H. Fast R-CNN
Fast R-CNN is an enhancement to the original Region-based Convolutional Neural Network object identification framework that intends to speed up and improve the efficiency of the object detection process. By proposing changes in both the region proposal and feature extraction stages, it overcame some of the computational and performance restrictions of region based networks that use convolutions. Fast R-CNN combines the entity detection and region proposal phases into a single model. Faster inference times result from the reduction of theneed to compute features for each area proposal separately.
Fast R-CNN, a clear and quick upgrade to R- CNN and SPPnet, is suggested in the study [12] by Ross Girshick. The author presents thorough experiments in addition to reporting cutting- edge detection results in the hopes of gaining fresh perspectives. Notably, sparse object proposals seem to enhance detector quality. Fast R-CNN makes it possible to investigate an issue that was previously too expensive (in terms of time) to do so.
I. Faster R-CNN
An enhanced object detection framework called Faster RCNN has greatly increased the speed and precision of object recognition in photos. Through the incorporation of the region proposal process into the neural network itself, it wascreated to alleviate some of the shortcomings of the original R-CNN framework. The object detection process was optimized by this integration, making it quicker and more effective.
Faster region based neural network, which is substantially faster than R-CNNand fast R-CNN, detects objects with great accuracy. It is now a well-liked option for numerous object identification applications.
Fig. 3. Some images from PlantVillage dataset.[23]
The suggested process in paper [14] consists of three fundamental components. The authors initially annotate the samples under investigation in order to determine the region of interest, which will then be used for Faster- RCNN training. In
2024 International Conference on Computing, Power, and Communication Technologies (IC2PCT)
Copyright © IEEE–2024 ISBN: 979-8-3503-8354-6 908
Authorized licensed use limited to: University of Texas of the Permian Basin. Downloaded on September 20,2024 at 10:01:59 UTC from IEEE Xplore. Restrictions apply.


order to detect and classify the several crop disorders using the predicted features, the model uses the network made using VGG-19. The research [14] on the PlantVillage database, a standard plant sample collection that is used extensively, demonstrated the effectiveness of the system for diagnosing plant diseases in arange of image-capturing settings. Fig 3 shows some random pictures from PlantVillage dataset[23].
J. Mask R-CNN
Mask R-CNN is unique in that it can do instance segmentation, which enables it to not only recognize objects in an image but also to separate each object at the pixel level. It is thus an effective tool for jobs requiring a more thorough comprehension of object boundaries. For each area suggestion, Mask R-CNN simultaneously completes three tasks: instance segmentation, bounding box regression, and object classification. Each task is handled by a different head. Because the architecture is fully convolutional, it can process images of various sizes without resizing or cropping them. As a result, Mask R-CNN is more adaptable. The ability to fine-tune and adapt the model to particular tasks is made possible by the availability of pre-trained models on huge datasets (like Common Objects in Context). The authors in paper [15] show that by supplementing a partition for forecasting an entity mask in aggregation with the prevailing partition for bounding box(bbox) detection, the technique, known as Mask R- CNN, extends Faster R-CNN. Specimen sectionalization, b-box entity depiction, and person core detection, of the COCO set of tasks, are among the three fields in which the authors [15] have demonstrated outstanding performance.
K. FCN
The acronym FCN stands for "Fully Convolutional Network." This is a specific type of design that uses neural networks made for the computer vision task of interpreting sectionalization, which entails assigning each picture component in a graphic to a certain object category or class. FCN excels in tasks that call for the understanding and localization of objects at the pixel level. For tasks involving interpretation of sectionalization process, where each image constituent in the picture is given a group heading designating the object or category to which it belongs, FCNs are generally used. Fine- grained object localization is offered by this. Two ended teaching of FCNs enables the arrangement as a whole to be optimised for segmentation tasks. Usually, training data consists of pixel-by-pixel annotated images. Numerous computer vision work, like image categorization, object detection, instance segmentation, and image-to-image translation, have found use for FCNs.
The authors in paper [16] have introduced the concept of FCNs. Modern classification convnets are a specific instance of convolutional networks, which constitute a diverse group of prototypes. As a result, the authors[16] have extended these classifying networks to categorization, to enhance the design with multiple resolution level amalgamations, and achieve a major improvement in the present state, while at the same time streamlining and accelerating teachings and results.
L. DBN
DBN stands for "Deep Belief Network." This is a form of neural network that is composed of several visible and hidden layers of interconnected units. DBNs are frequently employed in unsupervised machine learning applications like dimensionality reduction, generative modelling, and feature learning. They were first developed asa means to prepare deep neural networks for use, and they have significantly advanced the area of deep learning.
M. Deep CNN
A deep neural network that uses convolutions is a sort of neural network created importantly for processing and analysing visual input, such as photos and videos, and is referred to as a "deep CNN." Deep CNNs may learn complicated hierarchical features from the input data since they have numerous layers of convolutional and poolinglayers. They excel in several tasks, including entity detection, picture classification, and object recognition.
With the help of leaf photos, the authors in paper [17] suggested a unique fourteen levelled dense convolutional neural network (14-DCNN) for identifying disorders in plant leaves. A new dataset was formed by combining a number of available data collections. The techniques for augmenting the data were used to balance dataset's individual group dimensions.
N. Deep Denoising Autoencoder
In unsupervised machine learning, a Deep Denoising Autoencoder (DDAE) is a type of neural network developed artificially. It is an improvement on the standard autoencoder made to learn and represent data in a way that is more reliable and noise tolerant. DDAE’s main goal is to eliminate noise, rebuild clean data, and learn meaningful representations of the data.
For challenges involving the depiction of plant disorders, the authors in paper [18] suggested using autoencoders with denoising convolutions as both a denoiser and a feature identification. Fully connected network classifiers were then fed the output of the variational convolutional denoising autoencoders. Their tests [18] demonstrate that for applications requiring the identification of plant diseases, CNN structures perform better than fully deep connected architectures. In order to enhance the machine efficiency of the feature learning designs, the authors plan to examine impact of varying number features and use multicondition teaching by including many noise types.
O. YOLO
The popular real-time object identification system YOLO, which stands for "You Only Look Once," employs a single neural network to identify objects in pictures andvideos. YOLO is well renowned for its astounding speed andprecision, which makes it suited for a large number of systems, comprising of robots, autonomous cars, and monitoring systems. Fig 4 describes the YOLO-v5 architecture[24].
The proposed system [20] employs a cutting- edge method called “You Only Look Once” of the entity detection
2024 International Conference on Computing, Power, and Communication Technologies (IC2PCT)
Copyright © IEEE–2024 ISBN: 979-8-3503-8354-6 909
Authorized licensed use limited to: University of Texas of the Permian Basin. Downloaded on September 20,2024 at 10:01:59 UTC from IEEE Xplore. Restrictions apply.


methodology to identify plant diseases. YOLO processes leaf photos in real-time at a speed of forty five proportions per second. Before analysing the picture, it segregates the picture into several cells. One neural network makes only one evaluation to anticipate the b-boxes and group possibility. This improvises the efficiency and correctness of disease detection on leaves by a large factor.
Fig. 4. A YOLO-v5 architecture for plant disease detection system [24].
P. U-Net
The U-Net comprises of a decoder network that conducts pixel-wise segmentation and an encoder network that records contextual information. Because of the U-shape of the architecture, it is known as a "U-Net". The convolutional and pooling layers that make up the encoder path gradually decrease the spatial dimensions while increasing the depth. High- level features and context are captured by this section of the network. Convolutional and up sampling layers that gradually expand the spatial dimensions make up the decoder path. It produces pixelwise segmentation masks by fusing high-level features with local information and is symmetric to the encoder.
The authors in paper [19], suggested a hybrid deep learning model that uses a combination of deep learning methods to identify plant illnesses. The UNET deep learning system is used to identify and categorize diseases. Feature extraction and feature pooling are completed in the convolutional neural layer, and the condense level then segregates item to be tested. For evaluation, a large number of artificial and instantaneous plan datasets were employed. Two deep and two machine learning classifiers, including CNN, PCA, SVM and modified CNN, are assessed in a thorough experimental examination. The VGG16 and VGG16 backbone are combined to create the mCNN, which is used for classification and YOLOv3 model data preprocessing. On a heterogeneous dataset, the mCNN achieves detection and classification accuracy of 96.80%, outperforming both other and traditional classifiers.
Q. SegNet
To categorise each pixel in an image into a particular category or class, SegNet is a deep learning network created for semantic segmentation tasks. SegNet is a useful tool for computer vision applications like object recognition and scene comprehension because it was created for pixel-wise picture segmentation.
IV. LIMITATIONS OF EXISTING SYSTEMS
Although plant disease detection technologies have made tremendous strides in recent years, there are still certain constraints and difficulties with them. The following are some of the drawbacks of the technologies now available for use in plant disease detection systems:
1. Limited Dataset Diversity: Machine learning algorithms, which need big and diverse datasets for training, are used by many plant disease detection systems. It can be difficult to gather and annotate such datasets for varied plant diseases and species, though. Low number of data points might lead to decreased accuracy and generalization issues.
2. Hardware requirements: Some sophisticated detection techniques, like deep learning, need for a lot of memory and compute power, rendering them unavailable to farmers in areas with limited resources. These devices' hardware constraints can make field deployment difficult.
3. Environmental Variability: A disease's symptoms can be strongly impacted by environmental factors as weather, illumination, and soil types. Existing systems could find it difficult to take into account this unpredictability, which could lead to false positives or false negatives.
4. Real-time detection is a capability that many current systems lack. For farmers to combat diseases effectively, comments must be received right away. Crop loss can result from a delayed detection.
5. Dependence on access: For the transfer and processing of data, certain contemporary systems depend on internet access. This dependence may reduce the efficiency of illness identification in isolated or rural locations with low connection.
6. Current research is concentrated on creating more reliable, affordable, and user-friendly plant disease detection systems that may be extensively used by farmers and researchers, especially in areas where agriculture is a vital business. This research aims to solve these constraints.
V. CONCLUSION AND FUTURE SCOPE
The handling and identification of plant and crop pests has been immensely improvised by the use of the machine learning and deep learning technologies. Also, it is important to collect images from the plants at their various stages of growth so that the generalization and robustness of the detection system could be improved. Including plant health and meteorological information, like humidity and temperature, is pertinent for effective prediction and detection of plant disorders and pests’ diseases. Accumulating previous information of intelligent computers resembling human vision can be helpful in learning.
2024 International Conference on Computing, Power, and Communication Technologies (IC2PCT)
Copyright © IEEE–2024 ISBN: 979-8-3503-8354-6 910
Authorized licensed use limited to: University of Texas of the Permian Basin. Downloaded on September 20,2024 at 10:01:59 UTC from IEEE Xplore. Restrictions apply.


Connoisseurs from plant protection and agriculture are required to collaborate with themselves to achieve the full potential of the technology. The present advancement in making use of the methodologies for plant disease identification is explored in this paper. The future work would be to tackle the challenges of data availability and environmental variability as both parameters are subjected to change from place to place.
REFERENCES
[1] Shoaib, Muhammad and Shah, Babar and EI- Sappagh, Shaker and Ali, Akhtar and Ullah, Asad and Alenezi, Fayadh and Gechev, Tsanko and Hussain, Tariq and Ali, Farman An advanced deep learning modelsbased plant disease detection: A review of recent research,Frontiers in Plant Science, VOLUME 14,2023.
[2] Jayme Garcia Arnal Barbedo, A review on the main challenges in automatic plant disease identification based on visible range images,Biosystems Engineering,Volume 144,2016,Pages 52-60,ISSN 1537-5110, https://doi.org/10.1016/j.biosystemseng.2016.01.01 7.
[3] Chen, Hsing-Chung & Widodo, Agung & Wisnujati, Andika & Rahaman, Mosiur & Lin, Jerry & Chen, Liukui & Weng, Chien-Erh. (2022). AlexNet Convolutional Neural Network for Disease Detection and Classification of Tomato Leaf. Electronics. 11. 951.10.3390/electronics11060951
[4] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E. Hinton. 2017. ImageNet classification with deep convolutional neural networks. Commun. ACM 60, 6 (June 2017), 84–90. https://doi.org/10.1145/3065386
[5] K.Bhumika, Sirisha Madhuri T M Tech(Ph.D). ResNet based disease detection in wheat plants. International Journal of Creative Research Thoughts, Vol 10, Issue 6 June 2022, ISSN: 2320- 2882. https://ijcrt.org/papers/IJCRT22A6172.pdf
[6] Satwinder Kaur, Garima Joshi, Renu VigPlant Disease Classification using Deep Learning Google Net Model, International Journal of Innovative Technology and Exploring Engineering (IJITEE),ISSN: 22783075, Volume-8, Issue-9S, July 2019. https://www.ijitee.org/wpcontent/uploads/papers/v8i9S/I10510789S19.p df
[7] C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed, D. Anguelov, D. Erhan, V. Vanhoucke, and A. Rabinovich. Going deeper with convolutions. CoRR, abs/1409.4842, 2014.
[8] Gao Huang, Zhuang Liu, Laurens van der Maaten, Kilian Q. Weinberger. Densely Connected Convolutional Networks, CVPR 2017.
[9] Mahmoud Bakr, Sayed Abdel-Gaber, Mona Nasr, and Maryam Hazman. DenseNet Based Model for Plant Diseases Diagnosis. EJECE,European Journal of Electrical Engineering and Computer Science. ISSN: 27365751.
[10] Simonyan, Karen & Zisserman, Andrew. (2014). Very Deep Convolutional Networks for Large-Scale Image Recognition. arXiv 1409.1556.
[11] Falaschetti L, Manoni L, Di Leo D, Pau D, Tomaselli V, Turchetti C. A CNN-based image detector for plant leaf diseases classification. HardwareX. 2022 Sep 27;12:e00363. doi: 10.1016/j.ohx.2022.e00363. PMID: 36217500; PMCID: PMC9547307. [12] Girshick, Ross. (2015). Fast r-cnn. 10.1109/ICCV.2015.169 .
[13] Ren, Shaoqing & He, Kaiming & Girshick, Ross & Sun, Jian. (2016). Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks. 1-10.
[14] Nawaz, Marriam & Nazir, Tahira & Khan, Muhammad & Rajinikanth, Venkatesan & Kadry, Seifedine. (2023). Plant Disease Classification Using VGG-19 Based Faster-RCNN. 10.1007/978- 3-031-37940-6_23.
[15] He, Kaiming & Gkioxari, Georgia & Dollar, Piotr & Girshick, Ross. (2017). Mask R-CNN. 2980-2988. 10.1109/ICCV.2017.322.
[16] Long, Jonathan & Shelhamer, Evan & Darrell, Trevor. (2015). Fully convolutional networks for semantic segmentation. 34313440.10.1109/CVPR.2015.7298965.
[17] Pandian JA, Kumar VD, Geman O, Hnatiuc M, Arif M, Kanchanadevi K. Plant Disease Detection Using Deep Convolutional Neural Network. Applied Sciences. 2022; 12(14):6982. https://doi.org/10.3390/app12146982
[18] V. Zilvan, A. Ramdan, E. Suryawati, R. B. S. Kusumo, D. Krisnandi and H. F. Pardede, "Denoising Convolutional Variational Autoencoders-Based Feature Learning for Automatic Detection of Plant Diseases," 2019 3rd International Conference on Informatics and Computational Sciences (ICICoS), Semarang, Indonesia, 2019, pp. 1-6, doi: 10.1109/ICICoS48119.2019.8982494.
[19] P.M.SIVA RAJA, S.VIDHYA, R.P. SUMITHRA, K.RAMANAN, UNET-Based Deep Learning System for Disease Detection and Classification of Plants, PERIODICO di MINERALOGIA Volume 91, No. 5, 2022, ISSN: 0369-8963. https://periodicodimineralogia.it/wpcontent/uploads/2022/10/202291561. pdf
[20] A. Morbekar, A. Parihar and R. Jadhav, "Crop Disease Detection Using YOLO," 2020 International Conference for Emerging Technology (INCET), Belgaum, India, 2020, pp. 1-5, doi: 10.1109/INCET49848.2020.9153986.
[21] Murthy, Ch & Hashmi, Mohammad Farukh & Bokde, Neeraj & Geem, Zong Woo. (2020). Investigations of Object Detection in Images/Videos Using Various Deep Learning Techniques and Embedded Platforms—A Comprehensive Review. Applied Sciences. 10.3390/app10093280.
[22] Alzubaidi, L., Zhang, J., Humaidi, A.J. et al. Review of deep learning: concepts, CNN architectures, challenges, applications, future directions. J Big Data 8, 53 (2021). https://doi.org/10.1186/s40537-021-00444-8
[23] Hughes, D., Salathé, M. (2015). An open access repository of images on plant health to enable the development of mobile disease diagnostics. arXiv preprint arXiv:1511.08060, 1–7. doi: 10.48550/arXiv.1511.0806
[24] Chen, Z.; Wu, R.; Lin, Y.; Li, C.; Chen, S.; Yuan, Z.; Chen, S.; Zou, X. Plant Disease Recognition Model Based on Improved YOLOv5. Agronomy 2022, 12, 365. https://doi.org/10.3390/agronomy12020365
[25] Rezk, Nermeen & Attia, Abdel-Fattah & Elrashidy, Mohamed & ElSayed, Ayman & Hemdan, Ezz El-Din. (2022). An Efficient Plant Disease Recognition System Using Hybrid Convolutional Neural Networks (CNNs) and Conditional Random Fields (CRFs) for Smart IoT Applications in Agriculture. International Journal of Computational Intelligence Systems. 15. 10.1007/s44196-022-00129-x.
2024 International Conference on Computing, Power, and Communication Technologies (IC2PCT)
Copyright © IEEE–2024 ISBN: 979-8-3503-8354-6 911
Authorized licensed use limited to: University of Texas of the Permian Basin. Downloaded on September 20,2024 at 10:01:59 UTC from IEEE Xplore. Restrictions apply.