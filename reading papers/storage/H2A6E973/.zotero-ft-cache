MRI Information-based Correction and Restoration of
photoacoustic Tomography: Review
Vaibhav Nagrale
ECE Department, MANIT Bhopal, India nagrale111@gmail.com
Laxmi Kumre
ECE Department, MANIT Bhopal, India laxmikumre76@gmail.com
Vijayshri Chaurasia
ECE Department, MANIT Bhopal, India vijayshree21@gmail.com
Madhu Shandilya ECE Department, MANIT Bhopal India madhu_shandilya@yahoo.in
Abstract— Tomography is a method to get a series of detailed pictures of areas inside the body and Photoacoustic Tomography is a phenomenon in which ultrasound waves are generated by light absorbers in soft tissues exposed to a very short duration (~nanoseconds) pulsed laser beam in the near-infrared (NIR) region (wavelengths 700 to 1000 nm). There are several Tomography methods such as MRI (Magnetic Resonance Imaging), CT (Computer Tomography), and PET (Positron Emission Tomography). We get noise because of scattering coefficient μs and we get image because of absorbing coefficient μa. We have discussed the Dual-modality method for precise and more detailed images for different diagnosis methods. Our primary focus in this paper is to rectify the LF (Light Fluence) function. All three methods that we used are based on LF correction. Deoxyhemoglobin (Hb) and Oxyhemoglobin (HbO2) are used for spectral Unmixing. Spectral un-mixing is the process in which the measured spectrum of each mixed pixel is decomposed into its constituent spectra. To get accurate results statistical methods have been used like SSE, SNR, Err, and CNR. In this paper, the MRI-OS method has been discussed. Also, PAT-CS and PAT-OS methods are briefly explained.
Keywords—photo acoustic, MRI, PET, CT, tomography, tissues, light fluence, oxyhemoglobin, de-oxyhemoglobin
I. INTRODUCTION
Tomography was discovered by Godfrey Hounsfiel, who was a biomedical engineer. By contributing enormously towards the diagnosis of neurological disorders, he got the NOBEL prize in 1979 Optoacoustic Tomography also known as Photoacoustic Tomography, is also known for getting information about the human body like the brain, spin, and tissues. This information is in high resolution. These data are also useful for getting exact predictions of a disease. In our body, there are two types of tissues. Hard tissue is usually referring to bones, while soft tissue refers to muscle, tendons, or connective tissue. The absorption coefficient of hard tissues has less magnitude than soft tissues. Soft tissues have more blur images than hard tissues [1]-[3]. This is because photon released from LASER depends on two coefficients, one is Scattering coefficients and another one is Absorption coefficients and both of these are dependent on the softness of an object.[2]
When tissues are soft like the Kidney, Liver, and Brain, and when we are bombarded with laser light or RF pulses on soft tissues thermal expansion takes place due to the absorption of
photons and expands. Due to this, Acoustic waves are generated. The ultrasonic detector is used to form PAT images [5]-[6]. In this paper, eliminating the LF from the PAT image and recovering the distribution of the optical absorber is of great interest. LF distribution is the phenomenon in which radiation incidence on a unit sphere and unit is given per unit surface area of sphere per unit time.
The previous attempt to correct the LF effect from the PAT image involved dividing the image into organ levels and optimizing the optical parameter of each region to solve for the LF distribution. The MRI images have better resolution than PAT images. It is used to get images of soft tissues like kidneys, liver, etc.
There are different types of images raw PAT image (PAT), registered MRI image (rMRI), corrected PAT image (cPAT), and restored cPAT image (rcPAT) [18]. The incorporation of MRI information for PAT imaging could achieve improved LF correction and dual-modality joining image restoration. Dualmodality is the method in which MRI-PAT images are shown in which structural, functional, and Molecular information are shown simultaneously and allows for precise and more detailed images for different pre-clinical research applications.
Fig. 1. Difference between different types of Head scan
309
2024 16th International Conference on Computer and Automation Engineering
979-8-3503-7005-8/24/$31.00 ©2024 IEEE
2024 16th International Conference on Computer and Automation Engineering (ICCAE) | 979-8-3503-7005-8/24/$31.00 ©2024 IEEE | DOI: 10.1109/ICCAE59995.2024.10569732
Authorized licensed use limited to: University of Texas of the Permian Basin. Downloaded on September 20,2024 at 09:57:35 UTC from IEEE Xplore. Restrictions apply.


Magnetic Resonance Imaging (MRI) gives excellent anatomical definition and soft tissue contrast better than CT and PET. In CT X-rays are used which may affect the human body. In PET, a radioactive drug is used called a tracer to show a typical and atypical metabolic activity. While in MRI, radio waves are used which is safer than CT and PET. MRI makes it possible to improve target lesion positing and analysis of PET. Figure 1 shows different types of head scan images.
II. LITERATURE SURVEY
Spectral-unmixing is the technique in which the inverse problem in hyperspectral imaging aims at recovering the spectra of the pure constituents of an image (called end-members), as well as at estimating the proportions of said materials in each pixel (called abundances) [11]-[13]. Spectral-unmixing depends on the concentration of chromophore and molar extinction coefficient at particular wavelengths.
Pixel Spectral unmixing (Fig. 2) is the process of decomposing spectra into their constituent spectrum called 'ENDMEMBERS' and their corresponding fraction called 'ABENDANCE'.
y = 1m1 + 2m2 + 3m3 (1)
Fig.2. Spectral Un-mixing
From the above equation, ‘α’ is called ABUNDANCE, and ‘m’ is called 'ENDMEMBER'
(2)
A chromophore is responsible for the color of an object. The color seen by our eyes is the one not absorbed by the reflecting object within a certain wavelength spectrum of visible light. A chromophore is a part of a molecule whose presence is responsible for the color of a compound. It is the part of the molecule which when exposed to visible light will absorb and reflect a certain color.
Molar extinction coefficient (Fig. 3) is the measure of how strongly a substance absorbs light at a particular wavelength.
In this paper, we use a linear un-mixing method to calculate the distribution of Hb (Hemoglobin) and HbO2 (Oxyhemoglobin). After calculating the concentration of Hb and HbO2, we get the distribution of Oxygen Saturation (sO2).
Fig. 3. Molar extinction coefficient.
(3)
The pixel value in the PAT image is obtained by:
(4)
Where α denotes system response, Γ indicates thermo-elastic expansion parameter Φ denotes LF function, and μa and μs’ denote absorption and scattering coefficient. From the above formula, soft tissues have a small thermo-elastic Grüneisen parameter and are assumed to be constant.
By removing a constant term from the above equation and knowing the relationship between μs’ and μs which is
(5)
where g is Scattering anisotropy.
By removing the constant, we get
(6)
Therefore, PAT image P’ depends upon the Light Fluence function Φ and absorption coefficient.
The least-square optimization problems are those in which the error function is a quadratic function of parameters being optimized. The least-square optimization problem related to the Absorption coefficient is as follows:
(7)
In PAT image restoration based on MRI information, a regularization term J (x) can be added to the classic image restoration function as follows:
(8)
i i
i
i
a
i
a () =  () = c 
HbO Hb
HbO
cc
c
sO +
=
2
2 2
p(r ) a (r ) [(r ), a (r ), 's (r )]
 =        
(1 )
'g
s = s −
as a
p' ( ' ).
=
2
a = arg min p'−(a )a


=  − ' + ( ')
2
1
x' argmin x x 2 J x
310
Authorized licensed use limited to: University of Texas of the Permian Basin. Downloaded on September 20,2024 at 09:57:35 UTC from IEEE Xplore. Restrictions apply.


Fig. 4. Schematic diagram of PAT image correction and restoration based on MRI information
where x is the LF corrected PAT image, x' is the restored image and α ≥ 0 is the regularization parameter and J(x') is the regularization term. In the formula, a regularization term is added. The regularization term is added to the Loss function. The loss function is known as a function that computes the distance between the current output of the algorithm and the expected output. It is a measurement of how good your model is in terms of predicting the expected output.
III. METHODOLOGY
In this paper, three algorithms are discussed. One is MRI-OS and the other two methods are PAT-OS and PAT
CS. In PAT-OS algorithm which is also known as Photoacoustic Tomography – Organ Segmentation and PAT-CS is known as Photoacoustic Tomography – Counter Segmentation, and MRI-OS is known as Magnetic Resonance Image Tomography-Organ Segmentation. All three algorithms are used to improve LF function.
Segmentation is the process in which a digital image is divided into subgroups called image segments. This method is used to reduce the complexity of an image and to further process an image for more information. The common use of image segmentation is in object detection. It is not easy to process the entire image but it is convenient to process objects of interest in the image. Image segmentation improves accuracy and reduces inference time.
There are different types of image segmentation. But the main techniques are Semantic Segmentation, Instance Segmentation, and Panoptic Segmentation.
A. Semantic Segmentation:
Semantic Segmentation is the type in which each pixel in an image is divided into classes or objects. The goal is to create a dense pixel-wise segmentation of an image, where each image is assigned a specific object or class. It does not detect the difference between distinct entities within the same class. For example: all chairs are marked blue.
B. Instance Segmentation
Instance Segmentation identifies specific entities within the class. It is the unique form of image segmentation that is used for detecting each distinct instance of an object appearing in an image. Example: Different chairs are distinguished by different colors.
C. Panoptic Segmentation
Panoptic segmentation is an image-processing algorithm that combines Semantic segmentation and Instance segmentation to provide a comprehensive understanding of the scene. The goal of Panoptic Segmentation is to segment the region into semantically part of an image and also detect and differentiate segmented parts of regions.
There are 3 different types of image processing techniques:
(1) Edge-based Segmentation (2) Threshold-based Segmentation (3) Region-based Segmentation
D. Edge-based Segmentation
Edge-based segmentation is the technique that identifies the edges of various objects in a given image. To efficiently improve
311
Authorized licensed use limited to: University of Texas of the Permian Basin. Downloaded on September 20,2024 at 09:57:35 UTC from IEEE Xplore. Restrictions apply.


Edge-based segmentation, the boundaries of an image are significantly different from each other.
E. Threshold-based Segmentation
Threshold-based Segmentation is the simplest image segmentation method. In this method, pixels are divided based on their intensity based on their intensity relative to a given value or threshold. It is suitable to select a pixel value higher than the threshold.
F. Region-based Segmentation
Region-based Segmentation is the technique that divides images into small regions with similar characteristics. The process looks for the chunks of regions within the image.
In the PAT-OS method, only the background is segmented from the PAT image. It is an iterative method used to calculate the optical parameters to minimize the error between the raw PAT image and an estimated PAT image, which is equal to the product of the Light Fluence function and absorption coefficient.
PAT-CS also called 'Snakes' is an iterative region-growing image segmentation algorithm. In this algorithm, specify initial curves on an image and then use the active contour function to evolve the curves towards object boundaries. This method segments the object counter and assumes the uniform optical parameters within the imaged object and the LF map is calculated by manually selecting the absorption coefficients and scattering coefficients. Thus, its accuracy depends upon the choice of optical parameters.
In this paper, our interest is to find an LF correction method based on MRI-OS. The main motive of the MRI-OS method is to diagnose the disease accurately and fastly.[19]. We used two different types of images. i.e. MRI (Magnetic Resonance Imaging) and PAT (Photo acoustic Tomography). MRI image obtained from MRI machine and PAT image obtained from PAT generator.
Image registration is a process in which one image overlaps on another image and gets fine details. i.e. MRI image is registered with PAT image. Then, a Co-registered (rMRI) MRI image as prior information to segment the object from the organ level into several regions. Then, by using an optimization algorithm on rMRI, we get the LF function[Φ]. Again, we registered two images i.e. CPAT and rPAT. CPAT is LF corrected PAT image which is defined as
CPAT = PAT
Φ(μa,R) (9)
After registration, we get the rcPAT image (Image Restored by MRI-OS method)
IV. RESULTS
Fig. 5(a) shows the relationship between Error and number of iterations. Here Err depends on the Absorption coefficient. As the number of iteration increase, the convergence rate also increases. Fig 5(b) shows the Error between the PAT image and the Iterated PAT image. This figure's algorithm is sufficient to
converge within 10 iterations. Fig 5(c) shows the relation between SSE(Sum of Square Error) and standard Deviation of Noise. SSE is in between iPAT and the calculated absorption coefficient μa is small, indicating that our algorithm can solve the absorption coefficients with small errors in noisy PAT images.
Fig 5(d) gives us an error between ideal PAT and Corrected PAT images. Fig 5(c)(d) gives the relationship between SSE and Standard Deviation of Noise. Since the corrected PAT image (cPAT) contains noise, the SSE between iPAT and cPAT images increases with the noise standard deviation. Spectral unmixing method is used to detect the specific organ clearly because Oxygenated and Deoxygenated Hemoglobin have specific color. Deoxygenated Hemoglobin have red colour and Oxygenated Hemoglobin have blue colour. Multispectral Optoacoustic Tomography is also used on endogenous chromophore. By using spectral unmixing one get good segmented image which is useful for concluding diseases. Iterative methods are used to calculate the following results. The tool used is Light Fluence software which is used for brain segmentation. In this tool, uniform value of scattering coefficient μs and absorption coefficient μa are used which is needed for segmentation purpose.
Fig. 5. Measure of method performance
V. CONCLUSION
In this paper, we successfully removed noise from Biomedical Images. We used the Image Registration method, Light fluence correction method, and Restoration and Spectral Unmixing methods to improve the quality of images. We have successfully reduced SSE between the iterative PAT image and absorption coefficient. The proposed method finds its application in photo acoustic molecular imaging, tumor detection in microenvironment screening, and cancer metastasis tracking since it offers more precise spatial-temporal localization of targeted lesions.
312
Authorized licensed use limited to: University of Texas of the Permian Basin. Downloaded on September 20,2024 at 09:57:35 UTC from IEEE Xplore. Restrictions apply.


REFERENCES
[1] X. Li et al., “Multispectral interlaced sparse sampling photo acoustic tomography,” IEEE Trans. Med. Imag., vol. 39, no. 11, pp. 3463–3474, Nov. 2020, doi: 10.1109/TMI.2020.2996240.
[2] S. Mallidi, G. P. Luke, and S. Emelianov, “Photoacoustic imaging in cancer detection, diagnosis, and treatment guidance,” Trends Biotechnol., vol. 29, no. 5, pp. 21–213, May 2011, doi: 10.1016/j.tibtech.2011.01.006.
[3] S. Zhang et al., “Photoacoustic imaging of living mice enhanced with a low-cost contrast agent,” Biomed. Opt. Exp., vol. 10, no. 11,pp. 5744–5754, Nov. 2019, doi: 10.1364/BOE.10.005744.
[4] P. Beard, “Biomedical photoacoustic imaging,” Interface Focus, vol. 1, no. 4, pp. 31–602, Aug. 2011, doi: 10.1098/rsfs.2011.0028.
[5] X. Luís Deán-Ben and D. Razansky, “Adding fifth dimension to optoacoustic imaging: Volumetric time-resolved spectrally enriched tomography,” Light, Sci. Appl., vol. 3, no. 1, p. e137, Jan. 2014, doi: 10.1038/lsa.2014.18.
[6] Kazakeviciute, C. J. H. Ho, and M. Olivo, “Multispectral photoa- coustic imaging artifact removal and denoising using time series model- based spectral noise estimation,” IEEE Trans. Med. Imag., vol. 35, no. 9,pp. 2151–2163, Sep. 2016, doi: 10.1109/TMI.2016.2550624.
[7] B. T. Cox, J. G. Laufer, and P. C. Beard, “The challenges for quantitative photoacoustic imaging,” Proc. SPIE, vol. 7177, p. 717713, Feb. 2009.
[8] L. Qi et al., “Photoacoustic tomography image restoration with measured spatially variant point spread functions,” IEEE Trans. Med. Imag., vol. 40, no. 9, pp. 2318–2328, Sep. 2021, doi: 10.1109/TMI.2021.3077022.
[9] T. Cox, J. G. Laufer, P. C. Beard, and S. R. Arridge, “Quan- titative spectroscopic photoacoustic imaging: A review,” J. Bio- med. Opt., vol. 17, no. 6, Jun. 2012, Art. no. 061202, doi: 10.1117/1.JBO.17.6.061202.
[10] T. Cox, S. R. Arridge, K. P. Köstli, and P. C. Beard, “Two-dimensional quantitative photoacoustic image reconstruction of absorption distributions in scattering media by use of a simple iterative method,” Appl. Opt., vol. 45, no. 8, pp. 1866–1875, Mar. 2006, doi: 10.1364/AO.45.001866.
[11] L. Yao, Y. Sun, and H. Jiang, “Quantitative photoacoustic tomography based on the radiative transfer equation,” Opt. Lett., vol. 34, no. 12, pp. 7–1765, Jun. 2009, doi: 10.1364/ol.34.001765.
[12] T. Saratoon, T. Tarvainen, B. T. Cox, and S. R. Arridge, “A gradientbased method for quantitative photoacoustic tomography using the radiative transfer equation,” Inverse Problems, vol. 29, no. 7, Jul. 2013, Art. no. 075006, doi: 10.1088/0266-5611/29/7/075006.
[13] M. Brochu, J. Brunker, J. Joseph, M. R. Tomaszewski, S. Morscher, and S. E. Bohndiek, “Towards quantitative evaluation of tissue absorp- tion coefficients using light fluence correction in optoacoustic tomogra- phy,” IEEE Trans. Med. Imag., vol. 36, no. 1, pp. 322–331, Jan. 2017, doi: 10.1109/Tmi.2016.2607199.
[14] X. Li et al., “Model-based optoacoustic tomography image reconstruction with non-local and sparsity regularizations,” IEEE Access, vol. 7, pp. 102136–102148, 2019, doi: 10.1109/ACCESS.2019.2930650.
[15] W. Ren, H. Skulason, F. Schlegel, M. Rudin, J. Klohs, and R. Ni, “Automated registration of magnetic resonance imaging and optoacoustic
tomography data for experimental studies,” Neurophotonics, vol. 6, no. 2, Apr. 2019, Art. no. 025001, doi: 10.1117/1.NPh.6.2.025001.
[16] R. Ni, M. Vaas, W. Ren, and J. Klohs, “Noninvasive detection of acute cerebral hypoxia and subsequent matrix-metalloproteinase activity ina mouse model of cerebral ischemia using multispectral-optoacoustictomography,” Neurophotonics, vol. 5, no. 1, Jan. 2018, Art. no. 015005, doi: 10.1117/1.NPh.5.1.015005.
[17] B. Attia et al., “Multispectral optoacoustic and MRI coregistra- tion for molecular imaging of orthotopic model of human glioblas- toma,” J. Biophotonics, vol. 9, no. 7, pp. 8–701, Jul. 2016, doi: 10.1002/jbio.201500321. [18] Y. Ju et al., “Monodisperse Au–Fe2 C Janus nanoparticles: An attractive multifunctional material for triple-modal imaging-guided tumor photothermal therapy,” ACS Nano, vol. 11, no. 9, pp. 9239–9248, Sep. 2017, doi: 10.1021/acsnano.7b04461.
[19] W. Hupple, S. Morscher, N. C. Burton, M. D. Pagel, L. R. McNally, and J. Cárdenas-Rodríguez, “A light-fluence-independent method for the quantitative analysis of dynamic contrast-enhanced multispectral optoacoustic tomography (DCE MSOT),” Photoacoustics, vol. 10, pp. 54–64, Jun. 2018, doi: 10.1016/j.pacs.2018.04.003.
[20] M. Gehrung, M. Tomaszewski, D. McIntyre, J. Disselhorst, and S. Bohndiek, “Co-registration of optoacoustic tomography and magnetic resonance imaging data from murine tumour models,” Photoacoustics, vol. 18, Jun. 2020, Art. no. 100147, doi: 10.1016/j.pacs.2019.100147.
[21] W. Ren, X. L. Deán-Ben, M. Augath, and D. Razansky, “Development of concurrent magnetic resonance imaging and volumetric optoacoustic tomography: A phantom feasibility study,” J. Biophotonics, vol. 14, no. 2, Feb. 2021, Art. no. e202000293, doi: 10.1002/jbio.202000293.
[22] S. Zhang et al., “In vivo co-registered hybrid-contrast imaging by successive photoacoustic tomography and magnetic resonance imaging,” BioRxiv, 2021, doi: 10.1101/2021.03.06.434031.
[23] L. Qi et al., “Cross-sectional photoacoustic tomography image reconstruction with a multi-curve integration model,” Comput. Meth- ods Programs Biomed., vol. 197, Dec. 2020, Art. no. 105731, doi: 10.1016/j.cmpb.2020.105731.
[24] T. Jetzfellner, D. Razansky, A. Rosenthal, R. Schulz, K.-H. Englmeier, and V. Ntziachristos, “Performance of iterative optoacoustic tomography with experimental data,” Appl. Phys. Lett., vol. 95, no. 1, Jul. 2009, Art. no. 013703, doi: 10.1063/1.3167280.
[25] S. Mandal, X. L. Dean-Ben, and D. Razansky, “Visual quality enhancement in optoacoustic tomography using active contour segmentation priors,” IEEE Trans. Med. Imag., vol. 35, no. 10, pp. 22092217, Oct. 2016, doi: 10.1109/TMI.2016.2553156.
[26] M. Cabezas, A. Oliver, X. Lladó, J. Freixenet, and M. B. Cuadra, “A review of atlas-based segmentation for magnetic resonance brain images,” Comput. Methods Programs Biomed., vol. 104, no. 3, pp. e158–e177, Dec. 2011, doi: 10.1016/j.cmpb.2011.07.015.
313
Authorized licensed use limited to: University of Texas of the Permian Basin. Downloaded on September 20,2024 at 09:57:35 UTC from IEEE Xplore. Restrictions apply.