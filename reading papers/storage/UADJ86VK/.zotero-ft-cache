2024 Second International Conference on Emerging Trends in Information Technology and Engineering (ICETITE) | 979-8-3503-2820-2/24/$31.00 ©2024 IEEE | DOI: 10.1109/IC-ETITE58242.2024.10493751
2024 SecondIntemational Conference on Emerging Trends in Infonnation TechnologyandEngineering {ICETITE)
Detecting Fish Species through Mask RCNN
Rajeswari.A.M1, Afreeth.S2, Msal Baaqir.A3, Deepalakshmi.R4 Department ofComputer Science and Engineering Velammal College ofEngineering and Technology, Madurai, India 1arnrtce@gmail.com , 2afreeth.eng@gmail.com , 3afsalbaaqir@gmail.com , 4rdl@vcet.ac.in
Abstract - Detection of underwater fish species has become more important through marine science research. Automatic detection of fish species would facilitate the development of marine science. There are several different methods that can be employed to determine fish species. Each of the available methods requires a substantial amount of training data to detect precisely. To overcome this, in this article, we report on the findings of an investigation that was carried out utilizing an deep learning algorithm known as Mask Region based Convolution Neural Network (RCNN). The investigation was conducted using a dataset containing images of various types and directions of fish found in different parts of the world. Mask RCNN is able to produce the highest quality segmentation mask possible for every occurrence and different fish species with a high degree of accuracy. The mask RCNN is able to recognize and categorize fish species with an overall accuracy of almost 97%.
Keywords--augmentation, deep learning, fish species detection, mask R-CNN, segmentation.
I. INTRODUCTION
Properly categorizing fish species is essential for effective fisheries management and ecological research. Accurate and efficient recognition of fish species is essential for many reasons. These reasons include the identification of endangered species, determination of optimum harvest size or duration, ecosystem monitoring, and development of a smart production management system [ 1 ] . Through the development of its science and technology, China has made great strides in the field ofmariculture, that is, the cultivation of marine fish for commercial purposes. More than 70 percent of global mariculture production comes from China. Measurements of a fish's length, width and other morphological characteristics can be used in a variety of ways in smart mariculture [2]. Over the past few years, researchers have been developing methods to assess fish bodily characteristics through measurement [3] . To quantify fish characteristics, such as their eyes, bodies and pedicels, image processing technology is routinely applied [4]. Most fisheries still use the laborious and time-consuming method of manually identifying fish species, which may also interfere with the natural behaviour of fish.
To address the above concern, we present an automatic detection and classification approach for fish species, which can be used in smart mariculture. There are a lot of problems with camera images, such as inconsistent levels of brightness and darkness. This research offers an RCNN based method. RCNN, the Regional-Based Convolution Neural Network, is a type of machine learning model that is used for computer vision tasks, in particular for object detection. A variant, Mask RCNN is a popular deep learning instance segmentation technique that performs pixel-level segmentation on detected objects to segment and measure morphological traits in fish to address the aforementioned
979-8-3503-2820-2/$3 1 .00 ©2024 IEEE
issues. With Mask RCNN, it is possible to segment and measure the morphological characteristics of fish in an automated, accurate and effective manner. The system is designed to help researchers and environmentalists analyze camera imagery of fish to detect and categorize them into species. During the detection process, the system automatically adjusts for different levels of light, brightness, etc.
Therefore, the remainder of the paper points to the discussion of the literature survey in Section II. The working principles of the RCNN mask in Division III. The findings and discussions are set out in Section IV. And lastly the Conclusion and future work in Section V.
II. LITERATURE SURVEY
The literature review provides relevant insights, methodological responses and research findings. Critical analysis of the available data highlights inconsistencies and differences between different approaches to the subject's study.
To ensure accuracy, the author [5] elaborated a method in which the images were processed with an OFA implementation in FIET. This method outperforms competitors in terms of precision and sensing performance. The method was used by the author [2], who obtained a large precision of approximately 42%. They used, six different fish species using small Convolution Neural Networks to classify a wide range of pelagic fish species. The author's work [6] with convolution neural networks (CNN) and Open CV in a Python/MATLAB application allowed obtaining accuracy between 80% and 91%. The YOLOv4-based fish species selection program submitted by the author [4] is a fully developed model with a 9 1 . 67% success rate. The deep convolution neural networks used by the author [7] to identify fish species have reached greater detection accuracy than other systems. Using cutting-edge tools such as SPP (Spatial Pyramid Pooling) and DenseNet (dense neural networks), the author [8] achieved a 94% accuracy rate in classification. The author in his work [9] detected fish species using YOLOv4-tiny detection pattern and obtained an accuracy of 9 1 . 67%. Optical Fish Detection Network, a deep convolution neural network (OFDNet) [ 1 0] was introduced by the author and obtained an accurate score of 66. 7%. Dewan et al., [ 1 1] utilized technologies such as KNN (K-Nearest neighbor) and SVM (Support Vector Machine) that helped identify fish species. For detecting and tracking the fish, Lantsova et al., [ 1 2] has proposed methods such as background subtraction, Kalman filtering and acquiring satisfactory accuracy values. Xu et al., [13] used a system of differential equations to forecast the distribution of fish within a given region. Pre-formed convolution neural network models such as VGG, ResNet [ 14] were applied by the author and obtained efficient functionalities for retrieving content from applications. The author [ 1 5] identified fish
1
Authorized licensed use limited to: University of Texas of the Permian Basin. Downloaded on September 20,2024 at 09:58:54 UTC from IEEE Xplore. Restrictions apply.


2024 Second International Conference on Emerging Trends in Information Technology and Engineering (ICETITE)
species with few multiple domains, which was achieved set of predefined Bounding boxes that will be randomly using technologies linked to convolution neural networks. adjusted to adapt to the objects in the input image. Therefore, Marine species were monitored, categorized and detected as a complement, the Mask RCNN is integrated with the through in-depth learning approaches by the author [16]. Anchor Box algorithm to improve the precision of the
Of all the techniques used, small convolution neural networks are relatively less specific than others. Deep learning with the MobileNet model has shown a greater degree of accuracy in detecting fish underwater. Existing works of art also have limitations, such as models that require large amounts of formation data or are not applicable to clustered images. The mask RCNN model could bridge this gap.
Ill. PROPOSED MASK RCNN METHOD
For detection of fish species, we used a deep learning algorithm called Mask RCNN. This includes the boundary box methodology for image recognition, the instance segmentation to segment each image individually, and the mini-mask method for image classification. RCNN Mask framework for detecting fish species is shown in Fig. 1 .
r----------------------1
II
I OJI
I =I
! I Image Detection ] �"' !I
: {E.:
'----------------------·
1
Inference
Fig. 1. Mask RCNN Framework for fish species detection.
A. Dataset Used
Twenty-five images of three distinct fish (Gilt Head Bream, Red Mullet, and Black Sea Sprat) species as in Fig.2 are considered as the input images. Data on fish species were gathered from [ 17]. "Vgg Image Annotator" was used to generate a synthesized dataset of fish species. The annotated pictures ofthe fish species are represented on Fig. 3. Instance segmentation, unlike semantic segmentation, groups pixels into classes, and localizes and isolates each separate object within an image.
B. Algorithm
The boundary box algorithm forms an imaginary rectangular box defining the coordinates of interest of the X, Y element which are annotation markers drawn around the individual object of an image. Fig. 4 shows a sample bounding box algorithm result of a fish with its tag and the accuracy of the detection of the object. Anchor boxes are a
bounding boxes. This method has been adopted to more accurately segment and map images. Fig. 5 illustrates examples of anchor boxes produced for fish. Mask RCNN is an expansion of the Faster R-CNN object detection algorithm, which adds a segmentation branch to generate masks for each object found. The Mini-Mask algorithm was used for detecting and segmenting objects in images. Fig. 6 shows an example ofthe masked image ofthe fish.
Having masked the object and fixed the bounding box of the object, the RCNN Mask classifies the object by labeling it. Fig. 7 depicts the fish species classified from the sample in the input image.
Fig. 2. Fish species sample dataset
Fig. 3. Samples images of annotated images of fish species.
Fig. 4. Bounding Box generated for the fish identification.
2
Authorized licensed use limited to: University of Texas of the Permian Basin. Downloaded on September 20,2024 at 09:58:54 UTC from IEEE Xplore. Restrictions apply.


2024 Second International Conference on Emerging Trends in Information Technology and Engineering (ICETITE)
Fig. 5. The radom anchor boxes generated to fixthe bounding box.
Fig. 6. Masked image of a fish - the outcome ofmini-mask algorithm.
Fig. 7. Sample fish specied classied by the Mask RCNN algorithm.
IV. RESULTS AND DISCUSSIONS
For experimental assessment we have detected the fish species using the Bounding Box method, Instance Segmentation method and finally the combination of RCNN mini-mask along with anchor box algorithm. The result achieved has been captured and displayed in the Table 1 . At first, during the training phase, when the fish species is detected by the bounding box algorithm alone, we have achieved an accuracy of 33% only. To enhance this, we have used bounding box and the instance segmentation combination from which, the accuracy has raised to 92%. Finally, by using the mini-mask and anchor boxes combination, the model accuracy has reached at most to 96%. This can be inferred from the Table 1 for the three different species we have considered. Thus the accuracy has reached higher than the accuracy of the methods discussed in the literature survey.
Epoch is defined as the number of passes or steps taken by the algorithm to scan the entire dataset once. As we have dealt with the image dataset, we have considered 5 epochs to train our model. The model evaluation metrics like Precision, Recall and Accuracy are considered for each epoch results. The quality of classification models in machine learning is evaluated through the use of accuracy, precision, and recall. The accuracy shows the overall correct frequency of an ML classification model. Precision quantifies the accuracy of an ML model in predicting the target class. Recall indicates whether an ML pattern can find all objects in the target class.
TABLE I. INFERENCE OF FISH SPECIES DETECTION
Methodology Used Accuracy (%)
SpeciesI Species2 Species3
Bounding Box 32.54 33.01 33 .60
Bounding Box with Instance 89.71 90.12 92.34
Segmentation RCNN Mini-mask with Anchor 95.77 96.20 97.35
box
Fig. 8 illustrates the results of each epoch of our trained model for fish species detection using the Mask RCNN algorithm. From the graph depicted in Fig. 8, it is understood that the accuracy of the Mask RCNN algorithm has improved as the number of epoch increased and almost got saturated in the maximum of 5 epochs. Similarly the Precision and Recall measures have improved and got almost saturated in the 5th epoch.
Mask RCNN Performance in Fish Species Detection
1
0.95
0.9 �
0.85
0.8
0.75 Epochl Epoch2 Epoch3 Epoch4 EpochS
- Precision 0.8913 0.9255 0.9342 0.9401 0.9426
Recall 0.8473 0.9077 0.9211 0.9286 0.9312
Accuracy 0.9572 0.9723 0.9759 0.9781 0.9791
Fig. 8. Sample fish species classied by the Mask RCNN algorithm.
V. CONCLUSION
The discussion revolves around the need to detect fish species in marine science research. A survey and discussion are carried out on the existing methods and their limitations. The proposed approach, which is based on RCNN, is considered. The Mask RCNN evaluation datasets are described too. A detailed discussion is provided on the working principles of Mask RCNN, the proposed method. After analyzing the results generated by the proposed method, we discovered that it generated a remarkable segmentation mask for the input. This resulted in the final results being more accurate. Recognizing and categorizing fish species can be done by the Mask RCNN with an accuracy of almost 97%.
In the future, we aim to refine the proposed method and implement it in the archaeology department to examine artifacts.
3
Authorized licensed use limited to: University of Texas of the Permian Basin. Downloaded on September 20,2024 at 09:58:54 UTC from IEEE Xplore. Restrictions apply.


2024 Second International Conference on Emerging Trends in Information Technology and Engineering (ICETITE)
REFERENCES
[1] H. Wang, Y. Shi, Y. Yue and H. Zhao, "Study on Freshwater Fish Image Recognition Integrating SPP and DenseNet Network," 2020 IEEE International Conrerence on Mechatronics and Automation (ICMA), Beijing, China, 2020, pp. 564-569, doi: 1 0. 1 1 09/ICMA492 1 5.2020.9233696.
[2] Y. Li, D. Zhu and H. Fan, "An Improved Faster RCNN Marine Fish Classification Identification Algorithm," in 2021 2nd International Confurence on Artificial Intelligence and Computer Engineering (ICAICE), Hangzhou, China, 2021 pp. 126-129. doi: 1 0. 1 1 09/ICAICE54393.202 1 .00033.
[3] N. Petrellis, "Fish Morphological Feature Recognition Based on Deep Learning Techniques," 2021 l Oth International Conference on Modern Circuits and Systems Technologies (MOCAST), Thessaloniki, Greece, 202 1 , pp. 1 -4, doi: 1 0. 1 1 09/MOCAST52088.202 1 .9493407.
[4] D. A. Jimenez Nixon, "Computer vision neural network using YOLOv4 for underwater fish video detection In Roatan, Honduras," 2021 IEEE International Conference on Machine Learning and Applied Network Technologies (ICMLANT), Soyapango, El Salvador, 2021, pp. 1 -5, doi: 1 0. 1 1 09/ICMLANT53 1 70.202 1 .9690561 .
[5] A. K. Agarwal, R. G. Tiwari, V. Khullar and R. K. Kaushal, "Transfer Learning Inspired Fish SpeciesClassification," 2021 8th International Conrerence on Signal Processing and Integrated Networks (SPIN),Noida, India, 202 1 , pp. 1 1 54-1 159, doi: 1 0. 1 1 09/SPIN52536.202 1 .9566067.
[6] V. Pagire and A. Phadke, "Underwater Fish Detection and Classification using Deep Learning," 2022 International Conference on Intelligent Controller and Computing for Smart Power (ICICCSP), Hyderabad, India, 2022, pp. 1 -4, doi: 1 0. 1 1 09/ICICCSP53532.2022.98624 1 0.
[7] O.Ulucan, D.Karakaya, and M.Turkan, "A large-scale dataset for fish segmentation and classification", In2020 Innovations in Intelligent Systems and Applications Conference (ASYU), 2020, pp. 1 -5, IEEE. doi: 1 0. 1 1 09/ASYU5071 7.2020.9259867.
[8] M. Paraschiv, R. Padrino, P. Casari and A. Fernandez Anta, "Very Small Neural Networks for Optical Classification of Fish Images and Videos.", In Global OCEANS 2020: Singapore-US Gulf Coast, 2020, pp. 1 -7. IEEE, doi: 1 0. 1 1 09/IEEECONF38699.2020.9388986.
[9] C. J. L. Chan, E. J. A. Reyes, N. B. Linsangan and R. A. Juanatas, "Real-time Detection of AquariumFish Species Using YOLOv4-tiny
on Raspberry Pi 4," IEEE International Conference on Artificial Intelligence in Engineering and Technology, Kota Kinabalu, Malaysia, 2022, pp. 1 - 6, doi: l 0 . 1 1 09/IICAIET55 1 39.2022.9936790.
[10] J. H. Christensen, L. V. Mogensen, R. Galeazzi and J.C. Andersen, "Detection, localization and classification of fish and fish species in poor conditions using convolutional neural networks." In 20 1 8 IEEE/OES Autonomous Underwater Vehicle Workshop (AUV), pp. 1 -6. IEEE, 20 18.
[11] J. Dewan, A. Gele, 0. Fulari, B. Kabade and A. Joshi, "Fish Detection and Classification," 6th International Conference On Computing, Co=unication, Control And Automation (ICCUBEA, Pune, India, 2022, pp. 1 -5, doi: 1 0. 1 1 09/ICCUBEA54992.2022.10010836.
[12] E. Lantsova, T. Voitiuk, T. Zudilova and A. Kaarna, "Using low quality :'ideo sequences for fish detection and tracking," 2016 SAl Computmg Conference (SAl), London, UK, 2016, pp. 426-433, doi: 1 0. 1 1 09/SAI.20 16.7556017.
[13] B. Xu, X. Li and Y. Shen, "Fish detection based on grey-markov model," 2020 2nd International Conference on Applied Machine Learning (ICAML), Changsha, China, 2020, pp. 322-328, doi: 1 0. 1 1 09/ICAML5 1583.2020.00072.
[14] A. K. Agarwal, R. G. Tiwari, V. Khullar and R. K. Kaushal, "Transfer Learning Inspired Fish Species Classification," 2021 8th International Co�ference on Signal Processing and Integrated Networks (SPIN), N01da, India, 202 1 , pp. 1 1 54-1 159, doi: 1 0. 1 1 09/SPIN52536.202 1 .9566067.
[15] D. A. Konovalov, A. Saleh, M. Bradley, M. Sankupellay, S. Marini and M. Sheaves, "Underwater Fish Detection with Weak Multi Domain Supervision," 20 1 9 International Joint Conference on Neural Networks (IJCNN), Budapest, Hungary, 2019, pp. 1 -8, doi: l 0. 1 1 09/IJCNN.201 9.885 1 907.
[16] M. Bhanumathi and B. Arthi, "Future Trends and Short- Review on Fish Species Classification Models Based on Deep Learning Approaches," 2022 International Conference on Augmented Intelligence and Sustainable Systems (ICAISS), Trichy,India, 2022, pp. 0 1 -05, doi: 1 0. 1 1 09/ICAISS55 1 57.2022.1001 1087.
[17] 0. Ulucan, D. Karakaya, and M. Turkan, "A large-scale dataset for fish segmentation and classification", In 2020 Innovations in Intellige�t Systems and Applications Conference (ASYU), IEEE, 2020, doe 1 0. 1 1 09/ASYU50717.2020.9259867.
4
Authorized licensed use limited to: University of Texas of the Permian Basin. Downloaded on September 20,2024 at 09:58:54 UTC from IEEE Xplore. Restrictions apply.