{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b7a980b-e953-46fc-8afa-0e3519c9b5d8",
   "metadata": {},
   "source": [
    "# Datasets\n",
    "\n",
    "\n",
    "| **Dataset Name** | **Ground Truth** | **number of images** | **Reslution** | \n",
    "|------------------|-----------------|----------------|----------------|\n",
    "| **CVC-ColonDB(2013, Spain)** |Binary Mask | 380 | 500â€‰Ã—â€‰574 |\n",
    "| **ETIS-LaribPolypDB(2014, France)** | Binary Mask | 196 | 1225â€‰Ã—â€‰966 |\n",
    "| **CVC-ClinicDB(2015, Spain)** | Binary Mask| 612 | 576â€‰Ã—â€‰768 |\n",
    "|**ASU-Mayo polyp database(2016, America)**|Binary Mask and bounding box| 18,781 | 512â€‰Ã—â€‰512| \n",
    "|**GI lesions in Regular Colonoscopy(2016, France)**|Annotated file and bounding box in videos|30 frames | 768â€‰Ã—â€‰576 pixels|\n",
    "|**EndoScene(2016, Secondary dataset)**|Binary mask|912  | 224â€‰Ã—â€‰224|\n",
    "| **CVC-ClinicVideoDB(also named CVC-612)(2017)** | Binary Mask | 11,954 | 384 Ã— 288|\n",
    "| **Kvasir-SEG(2019, Secondary dataset)** | Binary mask and bounding box | 1000 | 320â€‰Ã—â€‰320| \n",
    "| **KvasirCapsule-SEG(2019)** | Bounding box | 47,238 | * |\n",
    "| **NBIPolyp-Ucdb(2019, Portugal)** |Binary mask| 86 | 576x720 |\n",
    "| **WLPolyp-UCdb(2019, Portugal)**|Annotated file|3040| 726â€‰Ã—â€‰576 | \n",
    "| **KUMC(2020, Secondary dataset)**|Bounding box|*| 224â€‰Ã—â€‰224 | \n",
    "| **SUN(2020, Japan)**|Bounding box|49,136 polyp + 109,554 non-polyps| 416â€‰Ã—â€‰416 | \n",
    "| **PICCOLO(2020, Spain)**|Binary mask|3433| 854â€‰Ã—â€‰480 | \n",
    "| **CP-CHILD(2020, China)**|Annotated file|9500| 256â€‰Ã—â€‰256 | \n",
    "| **EDD2020(2020)** | Bounding box and binary mask | * | * |\n",
    "| **HyperKvasir(2020)** | Binary Mask | 10,662 | 224 Ã— 224 |\n",
    "| **Kvasir-Capsule(2021)** | Bounding box | * | * |\n",
    "| **LD Polyp Video(2021, China)**|Bounding box|40,187| 560â€‰Ã—â€‰480 | \n",
    "| **SUN-SEG(2022, Secondary dataset)**|Binary mask, bounding box, scribble, and polygon||416â€‰Ã—â€‰416|\n",
    "| **PolypGen(2022, Multi-sites)** | Binary mask and bounding box | 6282 | 384â€‰Ã—â€‰288 to 1920â€‰Ã—â€‰1080|\n",
    "\n",
    "\n",
    "## References\n",
    "\n",
    "[Public Imaging Datasets of Gastrointestinal Endoscopy for Artificial Intelligence: a Review](https://pmc.ncbi.nlm.nih.gov/articles/PMC10584770/)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4722ba-2ed0-4f9d-80cf-629a17370c79",
   "metadata": {},
   "source": [
    "# Comprehensive List of Medical Image Segmentation Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9926fc0-cf89-4123-b409-6aa412faf667",
   "metadata": {},
   "source": [
    "### Classic and CNN-Based Architectures\n",
    "\n",
    "- **U-Net / U-Net++**: Skip connections and nested dense blocks for precise medical image segmentation.  \n",
    "- **Attention U-Net**: Adds attention gates to U-Net for focus on relevant regions.  \n",
    "- **DoubleU-Net**: Combines two U-Nets with VGG16/19 for enhanced feature extraction.  \n",
    "- **ResUNet**: Integrates residual blocks into U-Net to avoid vanishing gradients.  \n",
    "- **ResUNet++**: Improves ResUNet with squeeze-and-excitation and attention mechanisms.  \n",
    "- **ResUNet++ + CRF**: Adds Conditional Random Fields for post-processing refinement.  \n",
    "- **PraNet**: Parallel reverse attention network for polyp segmentation.  \n",
    "- **UACANet-S / UACANet-L**: Uncertainty-aware context aggregation for small/large polyps.  \n",
    "- **ColonSegNet**: Lightweight architecture optimized for colonoscopy images.  \n",
    "- **DDANet**: Dual-decoder attention network for multi-scale feature fusion.  \n",
    "- **DeepLabv3+ (Xception / MobileNet)**: Atrous convolution with Xception (high accuracy) or MobileNet (efficiency).  \n",
    "- **HRNetV2-W18-Smallv2 / HRNetV2-W48**: Maintains high-resolution features throughout the network.  \n",
    "- **MSRF-Net / MSRFE-Net**: Multi-scale residual fusion with/without edge guidance.  \n",
    "- **ESFPNet-L**: Enhanced feature pyramid network for real-time segmentation.  \n",
    "- **NanoNet-A / NanoNet-C**: Ultra-lightweight models (A: higher accuracy, C: compact).  \n",
    "\n",
    "---\n",
    "\n",
    "### Transformer-Based & Hybrid Architectures\n",
    "- **TransUNet**\n",
    "- **UNETR** (UNEt TRansformer)\n",
    "- **Swin-Unet**\n",
    "- **SegFormer**\n",
    "- **SETR** (SEgmentation TRansformer)\n",
    "- **Swin-UNETR**\n",
    "- **TransBTS** (for 3D brain segmentation)\n",
    "- **MedT** (Medical Transformer)\n",
    "- **CoTr** (CNN + Transformer)\n",
    "- **FCB-Former / FCB-Former + SEP**\n",
    "- **FCB-SwinV2 Transformer**\n",
    "- **ViT-SAM-Med** (based on Segment Anything)\n",
    "\n",
    "---\n",
    "\n",
    "### Automated, Generalizable Models\n",
    "- **nnU-Net** (Self-configuring framework, SOTA for many challenges)\n",
    "- **AutoML-MIS** (AutoML for Medical Image Segmentation)\n",
    "\n",
    "---\n",
    "\n",
    "### Foundation Models for Medical Imaging\n",
    "- **MedSAM / SAM-Med3D** (adapting Metaâ€™s SAM for medical domain)\n",
    "- **Med3D** (Transfer learning for 3D medical imaging)\n",
    "- **CLIP-Med / BioViL** (vision-language pretraining for medical images)\n",
    "\n",
    "---\n",
    "\n",
    "### Specialized Models / Less Common but Noteworthy\n",
    "- **V-Net** (3D segmentation using volumetric convolutions)\n",
    "- **Tiramisu (DenseNet-based FCN)**\n",
    "- **SegCaps** (Capsule network for segmentation)\n",
    "- **RA-UNet** (Residual attention UNet)\n",
    "- **3D U-Net** (volumetric medical data)\n",
    "- **Efficient-UNet** (MobileNet/EfficientNet encoder for lighter inference)\n",
    "- **DANet** (Dual Attention Network for segmentation)\n",
    "\n",
    "---\n",
    "\n",
    "Would you like this filtered based on:\n",
    "- **Polyp / Colon-specific** segmentation?\n",
    "- **3D vs 2D segmentation?**\n",
    "- **Lightweight vs heavy models for real-time inference?**\n",
    "- **Segmentation with homomorphic encryption support?** (experimental space)\n",
    "\n",
    "Let me know how deep youâ€™d like to go into any category."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e29b8c7-7a04-4f86-bba1-c1d706a29d7e",
   "metadata": {},
   "source": [
    "# **Polyp / Colon-Specific Segmentation Models**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833a56f3-72e6-440a-b3a4-e3d45baf864a",
   "metadata": {},
   "source": [
    "### **Well-known & High-performing Models**\n",
    "| Model Name      | Key Characteristics |\n",
    "|----------------|---------------------|\n",
    "| **U-Net**      | Classic encoder-decoder, still a baseline for polyp |\n",
    "| **U-Net++**    | Nested skip connections for finer details |\n",
    "| **ResUNet / ResUNet++** | Residual blocks for better gradient flow |\n",
    "| **DoubleU-Net**| Two-stage U-Net improves detection of small polyps |\n",
    "| **PraNet**     | Reverse attention + boundary refinement (SOTA for many polyp sets) |\n",
    "| **ColonSegNet**| Designed for real-time segmentation on Kvasir/CVC |\n",
    "| **DDANet**     | Dilated dual attention blocks; excellent contextual modeling |\n",
    "| **UACANet-S / L**| Channel attention for focusing on polyp regions |\n",
    "| **MSRF-Net / MSRFE-Net**| Multi-scale residual fusion, good for size variation in polyps |\n",
    "\n",
    "---\n",
    "\n",
    "### **Transformer-based or Hybrid Architectures**\n",
    "| Model Name      | Key Characteristics |\n",
    "|----------------|---------------------|\n",
    "| **TransUNet**  | ViT + U-Net for better global context |\n",
    "| **Swin-UNet / Swin-UNETR** | Shifted window attention for spatial efficiency |\n",
    "| **FCB-Former / + SEP** | Combines convolution and transformer for colonoscopy segmentation |\n",
    "| **NanoNet-A / C** | Lightweight models for edge device deployment |\n",
    "\n",
    "---\n",
    "\n",
    "### **Lightweight / Real-time Models for Polyp Segmentation**\n",
    "| Model Name      | Key Characteristics |\n",
    "|----------------|---------------------|\n",
    "| **ColonSegNet**| Real-time speed with decent accuracy |\n",
    "| **NanoNet**    | Optimized for latency-sensitive tasks |\n",
    "| **PraNet (Lite)** | Variants available for mobile deployment |\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ“ˆ **Recent Winners / Leaders in Polyp Challenges**\n",
    "- **PraNet**: Dominant in 2019â€“2021 challenges (e.g., Kvasir-SEG, CVC-ClinicDB)\n",
    "- **DoubleU-Net**: Strong performer for multi-scale polyp detection\n",
    "- **FCB-Former**: Newer hybrid achieving SOTA results on ColonDB, EndoScene\n",
    "- **UACANet**: Good on small and camouflaged polyps\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238c14c2-f042-40db-9cb7-8da5a6ea8594",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
